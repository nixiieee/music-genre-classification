{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "924a1fbc-61d4-4b9d-8340-d8b094dba9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0597ad7-0eb4-4fc4-8373-8ef5597c7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier()\n",
    "model.load_model('model.pickle')\n",
    "scaler = pickle.load(open('scaler.pickle', 'rb'))\n",
    "classes = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1ad079-2e9a-44bb-85e8-d0b57923220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_file, sr):\n",
    "    features = {}\n",
    "    \n",
    "    chroma = librosa.feature.chroma_stft(y=audio_file, sr=sr)\n",
    "    features['chroma_stft_mean'] = [np.mean(chroma)]\n",
    "    features['chroma_stft_var'] = [np.var(chroma)]\n",
    "\n",
    "    rms = librosa.feature.rms(y=audio_file)\n",
    "    features['rms_mean'] = [np.mean(rms)]\n",
    "    features['rms_var'] = [np.var(rms)]\n",
    "\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio_file, sr=sr)\n",
    "    features['spectral_centroid_mean'] = [np.mean(spectral_centroid)]\n",
    "    features['spectral_centroid_var'] = [np.var(spectral_centroid)]\n",
    "    \n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio_file, sr=sr)\n",
    "    features['spectral_bandwidth_mean'] = [np.mean(spectral_bandwidth)]\n",
    "    features['spectral_bandwidth_var'] = [np.var(spectral_bandwidth)]\n",
    "    \n",
    "    rolloff = librosa.feature.spectral_rolloff(y=audio_file, sr=sr)\n",
    "    features['rolloff_mean'] = [np.mean(rolloff)]\n",
    "    features['rolloff_var'] = [np.var(rolloff)]\n",
    "    \n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio_file)\n",
    "    features['zero_crossing_rate_mean'] = [np.mean(zero_crossing_rate)]\n",
    "    features['zero_crossing_rate_var'] = [np.var(zero_crossing_rate)]\n",
    "\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(audio_file)\n",
    "    features['harmony_mean'] = [np.mean(y_harmonic)]\n",
    "    features['harmony_var'] = [np.var(y_harmonic)]\n",
    "    features['perceptr_mean'] = [np.mean(y_percussive)]\n",
    "    features['perceptr_var'] = [np.var(y_percussive)]\n",
    "    \n",
    "    features['tempo'] = librosa.feature.tempo(y=audio_file, sr = sr)[0]\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=audio_file, sr=sr)\n",
    "    for i, mfcc in enumerate(mfccs):\n",
    "        features[f'mfcc{i+1}_mean'] = [np.mean(mfcc)]\n",
    "        features[f'mfcc{i+1}_var'] = [np.var(mfcc)]\n",
    "\n",
    "    return pd.DataFrame.from_dict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36b6c49f-1535-4ab1-a74d-d984748f0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_chunk(model, audio_file, sr):\n",
    "    \"\"\"Predict for 3-second audio chunk\"\"\"\n",
    "    data = extract_features(audio_file, sr)\n",
    "    data = scaler.transform(data)\n",
    "    pred=model.predict(data)\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29874c3-81a1-4b89-b98a-54ab10c646d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_file(audio_file):\n",
    "    \"\"\"Break file into 3-second chunks, predcit for each chunk and select the most frequent answer\"\"\"\n",
    "    # read\n",
    "    y, sr = librosa.load(path)\n",
    "    # trim silence\n",
    "    audio_file, _ = librosa.effects.trim(y)\n",
    "\n",
    "    \n",
    "    votes = np.zeros(10)\n",
    "    \n",
    "    chunk_len = sr*3 # unit count per 3 seconds\n",
    "    chunk_count = len(audio_file)//chunk_len\n",
    "    for chunk_idx in range(chunk_count-1):\n",
    "        audio_chunk = audio_file[chunk_idx*chunk_len:(chunk_idx+1)*chunk_len]\n",
    "        label = predict_chunk(model, audio_chunk, sr)\n",
    "        votes[label] += 1\n",
    "    last_chunk = audio_file[(chunk_count-1)*chunk_len:]\n",
    "    label = predict_chunk(model, last_chunk, sr)\n",
    "    votes[label] += 1\n",
    "    \n",
    "    return classes[np.argmax(votes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "789788af-3229-4cc1-bfac-754656aa7f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classical'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/genres_original/classical/classical.00001.wav'\n",
    "predict_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6611969-bda3-46e0-98e8-bbdda890efe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
